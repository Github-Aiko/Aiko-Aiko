{
    "configuration": "配置",
    "model": "模型",
    "token": {
        "label": "最大 Token 数量",
        "description": "聊天完成时要生成的 Token 的最大数量。输入 Token 和生成 Token 的总长度受模型上下文长度的限制。"
    },
    "default": "默认值",
    "temperature": {
        "label": "温度",
        "description": "采样温度，介于 0 和 2 之间。较高的值（如 0.8）会使输出更随机，而较低的值（如 0.2）会使其更加专注和确定性。我们通常建议修改此项或 top p，但不建议同时修改两项。（默认值：1）"
    },
    "presencePenalty": {
        "label": "存在惩罚",
        "description": "介于 -2.0 和 2.0 之间的数字。正值会根据新 Token 是否出现在到目前为止的文本中对它们进行惩罚，增加模型谈论新话题的可能性。（默认值：0）"
    },
    "topP": {
        "label": "Top-p",
        "description": "介于 0 和 1 之间的数字。与温度采样不同的另一种方法是使用 nucleus 采样，其中模型考虑具有 top p 概率质量的 Token 的结果。因此，0.1 表示仅考虑构成前 10% 概率质量的 Token。我们通常建议修改此项或温度，但不建议同时修改两项。（默认值：1）"
    },
    "frequencyPenalty": {
        "label": "频率惩罚",
        "description": "介于 -2.0 和 2.0 之间的数字。正值会根据 Token 在到目前为止的文本中的现有频率对其进行惩罚，降低模型重复相同行的可能性。（默认值：0）"
    }
}