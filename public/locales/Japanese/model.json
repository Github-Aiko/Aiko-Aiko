{
    "configuration": "設定",
    "model": "モデル",
    "token": {
        "label": "最大トークン数",
        "description": "チャットの自動補完で生成するトークンの最大数。入力トークンと生成されたトークンの合計長は、モデルのコンテキスト長で制限されます。"
    },
    "default": "デフォルト",
    "temperature": {
        "label": "温度",
        "description": "サンプリング温度。0から2までの値を設定できます。0.8のような高い値は出力をよりランダムにし、0.2のような低い値はより焦点を絞って決定的にします。通常、これまたはTop-pを変更することをお勧めします。 （デフォルト：1）"
    },
    "presencePenalty": {
        "label": "プレゼンスペナルティ",
        "description": " -2.0から2.0の数値を設定できます。正の値は、トークンが既存のテキストに現れる頻度に基づいてペナルティを課し、モデルが新しいトピックについて話す可能性を高めます。 （デフォルト：0）"
    },
    "topP": {
        "label": "Top-p",
        "description": "0から1の数値を設定できます。温度との代替手段であるnucleus samplingで、モデルは上位p確率質量を持つトークンの結果を考慮します。 0.1は、確率質量の上位10％を占めるトークンのみが考慮されることを意味します。通常、これまたは温度を変更することをお勧めします。 （デフォルト：1）"
    },
    "frequencyPenalty": {
        "label": "頻度ペナルティ",
        "description": "-2.0から2.0の数値を設定できます。正の値は、既存のテキストでのトークンの頻度に基づいて新しいトークンにペナルティを課し、モデルが同じ行を完全に繰り返す可能性を減らします。 （デフォルト：0）"
    },
    "defaultChatConfig": "Default Chat Config",
    "defaultSystemMessage": "Default System Message",
    "resetToDefault": "Reset To Default"
}