{
    "configuration": "구성",
    "model": "모델",
    "token": {
        "label": "최대 토큰",
        "description": "채팅 완료 시 생성할 수있는 최대 토큰 수입니다. 입력 토큰과 생성된 토큰의 총 길이는 모델의 문맥 길이로 제한됩니다."
    },
    "default": "기본값",
    "temperature": {
        "label": "온도",
        "description": "샘플링 온도. 0에서 2 사이의 값으로, 값이 높을수록 (0.8과 같은) 출력이 더 무작위적이고, 값이 낮을수록 (0.2와 같은) 보다 집중적이고 결정적입니다. 일반적으로 이러한 값을 변경하는 것이 좋지만 두 값 (온도와 top p)을 모두 변경하는 것은 추천하지 않습니다. (기본값: 1)"
    },
    "presencePenalty": {
        "label": "Presence Penalty",
        "description": "-2.0에서 2.0 사이의 숫자. 양수 값은 새로운 토큰을 이전 텍스트에 나타난 여부에 따라 패널티를 부과하여 모델이 새로운 주제에 대해 이야기할 확률을 높입니다. (기본값: 0)"
    },
    "topP": {
        "label": "Top-p",
        "description": "0에서 1 사이의 숫자. 온도 샘플링 대안인 nucleus 샘플링으로, 모델이 상위 p 확률 질량을 가진 토큰의 결과를 고려합니다. 따라서 0.1은 상위 10 % 확률 질량을 구성하는 토큰만 고려합니다. 일반적으로 온도와 함께 이 값을 변경하는 것이 좋지만 두 값을 모두 변경하는 것은 추천하지 않습니다. (기본값: 1)"
    },
    "frequencyPenalty": {
        "label": "Frequency Penalty",
        "description": "-2.0에서 2.0 사이의 숫자. 양수 값은 새로운 토큰을 이전 텍스트에서의 기존 빈도수에 따라 패널티를 부과하여 모델이 동일한 줄을 반복하는 확률을 낮춥니다. (기본값: 0)"
    }
}